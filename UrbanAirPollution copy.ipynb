{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701bc70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import lightgbm as lgb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54c888b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./Train.csv')\n",
    "test_df = pd.read_csv('./Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89379433",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Place_ID' in train_df.columns and 'Date' in train_df.columns:\n",
    "    train_df = train_df.drop(['Place_ID', 'Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4823a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Place_ID X Date' in train_df.columns:\n",
    "    train_df[['Place_ID', 'Date']] = train_df['Place_ID X Date'].str.split(' X ', expand=True)\n",
    "    idx = train_df.columns.get_loc('Place_ID X Date')\n",
    "    train_df = train_df.drop('Place_ID X Date', axis=1)\n",
    "    train_df.insert(idx, 'Date', train_df.pop('Date'))\n",
    "    train_df.insert(idx, 'Place_ID', train_df.pop('Place_ID'))\n",
    "    train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
    "    train_df['Date'] = train_df['Date'].dt.strftime('%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b9c593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_groups = train_df.groupby('Place_ID')\n",
    "numeric_cols = train_df.select_dtypes(include=np.number).columns\n",
    "train_df[numeric_cols] = place_groups[numeric_cols].transform(lambda x: x.fillna(x.median()))\n",
    "train_df = train_df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e7c58ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\4629417.py:4: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  train_df['week'] = train_df['Date'].dt.week\n"
     ]
    }
   ],
   "source": [
    "train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
    "train_df['year'] = train_df['Date'].dt.year\n",
    "train_df['month'] = train_df['Date'].dt.month\n",
    "train_df['week'] = train_df['Date'].dt.week\n",
    "train_df['day'] = train_df['Date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a741b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['total_days_month'] = train_df['month'].apply(lambda x: 31 if x==1 else (28+31 if x==2 else (28+31+31 if x==1 else 28+30+31+31))) \n",
    "train_df['total_days'] = train_df['total_days_month'] + train_df['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ebbb189",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(['Place_ID', 'Date', 'target', 'target_min', 'target_max', 'target_variance', 'target_count'], axis=1)\n",
    "y_train = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee4f4a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trains, X_tests, y_trains, y_tests = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e102f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective' :'regression',\n",
    "    'learning_rate' : 0.03,\n",
    "    'num_iterations': 50000,\n",
    "    'max_bins': 50, \n",
    "    'max_depth' :7 ,\n",
    "    'num_leaves' : 70,\n",
    "    'feature_fraction': 0.64, \n",
    "    'bagging_fraction': 0.8, \n",
    "    'bagging_freq':1,\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'metric': 'rmse' ,\n",
    "     'min_data_in_leaf':5,\n",
    "    'reg_lambda' :100\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb3316bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1491: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via 'params' instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3806\n",
      "[LightGBM] [Info] Number of data points in the train set: 30557, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 61.148045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1491: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via 'params' instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[500]\ttraining's rmse: 18.4875\tvalid_1's rmse: 18.4875\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\ttraining's rmse: 13.5458\tvalid_1's rmse: 13.5458\n",
      "[1500]\ttraining's rmse: 10.409\tvalid_1's rmse: 10.409\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2000]\ttraining's rmse: 8.19657\tvalid_1's rmse: 8.19657\n",
      "[2500]\ttraining's rmse: 6.57529\tvalid_1's rmse: 6.57529\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3000]\ttraining's rmse: 5.34267\tvalid_1's rmse: 5.34267\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3500]\ttraining's rmse: 4.36959\tvalid_1's rmse: 4.36959\n",
      "[4000]\ttraining's rmse: 3.59885\tvalid_1's rmse: 3.59885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4500]\ttraining's rmse: 2.98342\tvalid_1's rmse: 2.98342\n",
      "[5000]\ttraining's rmse: 2.49131\tvalid_1's rmse: 2.49131\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5500]\ttraining's rmse: 2.08712\tvalid_1's rmse: 2.08712\n",
      "[6000]\ttraining's rmse: 1.7552\tvalid_1's rmse: 1.7552\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6500]\ttraining's rmse: 1.47973\tvalid_1's rmse: 1.47973\n",
      "[7000]\ttraining's rmse: 1.25305\tvalid_1's rmse: 1.25305\n",
      "[7500]\ttraining's rmse: 1.0639\tvalid_1's rmse: 1.0639\n",
      "[8000]\ttraining's rmse: 0.906527\tvalid_1's rmse: 0.906527\n",
      "[8500]\ttraining's rmse: 0.774012\tvalid_1's rmse: 0.774012\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9000]\ttraining's rmse: 0.662363\tvalid_1's rmse: 0.662363\n",
      "[9500]\ttraining's rmse: 0.568503\tvalid_1's rmse: 0.568503\n",
      "[10000]\ttraining's rmse: 0.488011\tvalid_1's rmse: 0.488011\n",
      "[10500]\ttraining's rmse: 0.419977\tvalid_1's rmse: 0.419977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11000]\ttraining's rmse: 0.363201\tvalid_1's rmse: 0.363201\n",
      "[11500]\ttraining's rmse: 0.313674\tvalid_1's rmse: 0.313674\n",
      "[12000]\ttraining's rmse: 0.271433\tvalid_1's rmse: 0.271433\n",
      "[12500]\ttraining's rmse: 0.23528\tvalid_1's rmse: 0.23528\n",
      "[13000]\ttraining's rmse: 0.204296\tvalid_1's rmse: 0.204296\n",
      "[13500]\ttraining's rmse: 0.177422\tvalid_1's rmse: 0.177422\n",
      "[14000]\ttraining's rmse: 0.154235\tvalid_1's rmse: 0.154235\n",
      "[14500]\ttraining's rmse: 0.134476\tvalid_1's rmse: 0.134476\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15000]\ttraining's rmse: 0.117223\tvalid_1's rmse: 0.117223\n",
      "[15500]\ttraining's rmse: 0.102242\tvalid_1's rmse: 0.102242\n",
      "[16000]\ttraining's rmse: 0.0894074\tvalid_1's rmse: 0.0894074\n",
      "[16500]\ttraining's rmse: 0.0781574\tvalid_1's rmse: 0.0781574\n",
      "[17000]\ttraining's rmse: 0.0684568\tvalid_1's rmse: 0.0684568\n",
      "[17500]\ttraining's rmse: 0.0599934\tvalid_1's rmse: 0.0599934\n",
      "[18000]\ttraining's rmse: 0.052566\tvalid_1's rmse: 0.052566\n",
      "[18500]\ttraining's rmse: 0.0460908\tvalid_1's rmse: 0.0460908\n",
      "[19000]\ttraining's rmse: 0.0404777\tvalid_1's rmse: 0.0404777\n",
      "[19500]\ttraining's rmse: 0.0355453\tvalid_1's rmse: 0.0355453\n",
      "[20000]\ttraining's rmse: 0.0312044\tvalid_1's rmse: 0.0312044\n",
      "[20500]\ttraining's rmse: 0.0274266\tvalid_1's rmse: 0.0274266\n",
      "[21000]\ttraining's rmse: 0.0241272\tvalid_1's rmse: 0.0241272\n",
      "[21500]\ttraining's rmse: 0.0212302\tvalid_1's rmse: 0.0212302\n",
      "[22000]\ttraining's rmse: 0.0187178\tvalid_1's rmse: 0.0187178\n",
      "[22500]\ttraining's rmse: 0.0165139\tvalid_1's rmse: 0.0165139\n",
      "[23000]\ttraining's rmse: 0.0145555\tvalid_1's rmse: 0.0145555\n",
      "[23500]\ttraining's rmse: 0.01283\tvalid_1's rmse: 0.01283\n",
      "[24000]\ttraining's rmse: 0.0113207\tvalid_1's rmse: 0.0113207\n",
      "[24500]\ttraining's rmse: 0.00999033\tvalid_1's rmse: 0.00999033\n",
      "[25000]\ttraining's rmse: 0.00880694\tvalid_1's rmse: 0.00880694\n",
      "[25500]\ttraining's rmse: 0.00778551\tvalid_1's rmse: 0.00778551\n",
      "[26000]\ttraining's rmse: 0.00687599\tvalid_1's rmse: 0.00687599\n",
      "[26500]\ttraining's rmse: 0.00608878\tvalid_1's rmse: 0.00608878\n",
      "[27000]\ttraining's rmse: 0.00538478\tvalid_1's rmse: 0.00538478\n",
      "[27500]\ttraining's rmse: 0.00476377\tvalid_1's rmse: 0.00476377\n",
      "[28000]\ttraining's rmse: 0.00421043\tvalid_1's rmse: 0.00421043\n",
      "[28500]\ttraining's rmse: 0.00372459\tvalid_1's rmse: 0.00372459\n",
      "[29000]\ttraining's rmse: 0.00329482\tvalid_1's rmse: 0.00329482\n",
      "[29500]\ttraining's rmse: 0.00291128\tvalid_1's rmse: 0.00291128\n",
      "[30000]\ttraining's rmse: 0.00257938\tvalid_1's rmse: 0.00257938\n",
      "[30500]\ttraining's rmse: 0.00228401\tvalid_1's rmse: 0.00228401\n",
      "[31000]\ttraining's rmse: 0.00202452\tvalid_1's rmse: 0.00202452\n",
      "[31500]\ttraining's rmse: 0.00179319\tvalid_1's rmse: 0.00179319\n",
      "[32000]\ttraining's rmse: 0.00158827\tvalid_1's rmse: 0.00158827\n",
      "[32500]\ttraining's rmse: 0.00140811\tvalid_1's rmse: 0.00140811\n",
      "[33000]\ttraining's rmse: 0.00124686\tvalid_1's rmse: 0.00124686\n",
      "[33500]\ttraining's rmse: 0.00110501\tvalid_1's rmse: 0.00110501\n",
      "[34000]\ttraining's rmse: 0.000980637\tvalid_1's rmse: 0.000980637\n",
      "[34500]\ttraining's rmse: 0.000868921\tvalid_1's rmse: 0.000868921\n",
      "[35000]\ttraining's rmse: 0.000770822\tvalid_1's rmse: 0.000770822\n",
      "[35500]\ttraining's rmse: 0.000684014\tvalid_1's rmse: 0.000684014\n",
      "[36000]\ttraining's rmse: 0.000606493\tvalid_1's rmse: 0.000606493\n",
      "[36500]\ttraining's rmse: 0.000538057\tvalid_1's rmse: 0.000538057\n",
      "[37000]\ttraining's rmse: 0.000477346\tvalid_1's rmse: 0.000477346\n",
      "[37500]\ttraining's rmse: 0.000423609\tvalid_1's rmse: 0.000423609\n",
      "[38000]\ttraining's rmse: 0.000375615\tvalid_1's rmse: 0.000375615\n",
      "[38500]\ttraining's rmse: 0.00033347\tvalid_1's rmse: 0.00033347\n",
      "[39000]\ttraining's rmse: 0.000295838\tvalid_1's rmse: 0.000295838\n",
      "[39500]\ttraining's rmse: 0.00026263\tvalid_1's rmse: 0.00026263\n",
      "[40000]\ttraining's rmse: 0.000232902\tvalid_1's rmse: 0.000232902\n",
      "[40500]\ttraining's rmse: 0.000206532\tvalid_1's rmse: 0.000206532\n",
      "[41000]\ttraining's rmse: 0.000183396\tvalid_1's rmse: 0.000183396\n",
      "[41500]\ttraining's rmse: 0.000163026\tvalid_1's rmse: 0.000163026\n",
      "[42000]\ttraining's rmse: 0.000144867\tvalid_1's rmse: 0.000144867\n",
      "[42500]\ttraining's rmse: 0.000128778\tvalid_1's rmse: 0.000128778\n",
      "[43000]\ttraining's rmse: 0.000114377\tvalid_1's rmse: 0.000114377\n",
      "[43500]\ttraining's rmse: 0.000101561\tvalid_1's rmse: 0.000101561\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44000]\ttraining's rmse: 9.02133e-05\tvalid_1's rmse: 9.02133e-05\n",
      "[44500]\ttraining's rmse: 8.00115e-05\tvalid_1's rmse: 8.00115e-05\n",
      "[45000]\ttraining's rmse: 7.11633e-05\tvalid_1's rmse: 7.11633e-05\n",
      "[45500]\ttraining's rmse: 6.32487e-05\tvalid_1's rmse: 6.32487e-05\n",
      "[46000]\ttraining's rmse: 5.61915e-05\tvalid_1's rmse: 5.61915e-05\n",
      "[46500]\ttraining's rmse: 4.99345e-05\tvalid_1's rmse: 4.99345e-05\n",
      "[47000]\ttraining's rmse: 4.43423e-05\tvalid_1's rmse: 4.43423e-05\n",
      "[47500]\ttraining's rmse: 3.94313e-05\tvalid_1's rmse: 3.94313e-05\n",
      "[48000]\ttraining's rmse: 3.50584e-05\tvalid_1's rmse: 3.50584e-05\n",
      "[48500]\ttraining's rmse: 3.11329e-05\tvalid_1's rmse: 3.11329e-05\n",
      "[49000]\ttraining's rmse: 2.76445e-05\tvalid_1's rmse: 2.76445e-05\n",
      "[49500]\ttraining's rmse: 2.45525e-05\tvalid_1's rmse: 2.45525e-05\n",
      "[50000]\ttraining's rmse: 2.18304e-05\tvalid_1's rmse: 2.18304e-05\n"
     ]
    }
   ],
   "source": [
    "# lgb_trains = lgb.Dataset(X_trains, y_trains, silent=False,categorical_feature=['year','month','day','week'])\n",
    "# lgb_evals = lgb.Dataset(X_tests, y_tests, silent=False,categorical_feature=['year','month','day','week'])\n",
    "lgb_trains = lgb.Dataset(X_train, y_train, silent=False,categorical_feature=['year','month','day','week'])\n",
    "lgb_evals = lgb.Dataset(X_train, y_train, silent=False,categorical_feature=['year','month','day','week'])\n",
    "model = lgb.train(params, train_set = lgb_trains, num_boost_round=10000,verbose_eval=500, valid_sets=[lgb_trains,lgb_evals])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e53ec9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_groups = test_df.groupby('Place_ID')\n",
    "numeric_cols = test_df.select_dtypes(include=np.number).columns\n",
    "test_df[numeric_cols] = place_groups[numeric_cols].transform(lambda x: x.fillna(x.median()))\n",
    "test_df = test_df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "24f885da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Place_ID' in test_df.columns and 'Date' in test_df.columns:\n",
    "    test_df = test_df.drop(['Place_ID', 'Date'], axis=1)\n",
    "if 'Place_ID X Date' in test_df.columns:\n",
    "    test_df[['Place_ID', 'Date']] = test_df['Place_ID X Date'].str.split(' X ', expand=True)\n",
    "    idx = test_df.columns.get_loc('Place_ID X Date')\n",
    "    test_df.insert(idx, 'Date', test_df.pop('Date'))\n",
    "    test_df.insert(idx, 'Place_ID', test_df.pop('Place_ID'))\n",
    "    test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
    "    test_df['Date'] = test_df['Date'].dt.strftime('%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bd3e7208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\655527865.py:4: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  test_df['week'] = test_df['Date'].dt.week\n"
     ]
    }
   ],
   "source": [
    "test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
    "test_df['year'] = test_df['Date'].dt.year\n",
    "test_df['month'] = test_df['Date'].dt.month\n",
    "test_df['week'] = test_df['Date'].dt.week\n",
    "test_df['day'] = test_df['Date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "568e7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['total_days_month'] = test_df['month'].apply(lambda x: 31 if x==1 else (28+31 if x==2 else (28+31+31 if x==1 else 28+30+31+31))) \n",
    "test_df['total_days'] = test_df['total_days_month'] + test_df['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "21116f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(['Place_ID X Date','Place_ID', 'Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cf4a7c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "22f81559",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({\n",
    "    'Place_ID X Date': test_df['Place_ID X Date'],\n",
    "    'target': test_pred\n",
    "})\n",
    "output_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd8fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
